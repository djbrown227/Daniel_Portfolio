{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b97b7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There isnt enough data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stand_test = pd.read_csv(r\"C:\\Users\\djbro\\OneDrive\\Desktop\\Multiple Linear Regression\\Testing\\pisa2009test.csv\")\n",
    "stand_test1= pd.read_csv(r\"C:\\Users\\djbro\\OneDrive\\Desktop\\Multiple Linear Regression\\Testing\\pisa2009train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f5400e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>male</th>\n",
       "      <th>raceeth</th>\n",
       "      <th>preschool</th>\n",
       "      <th>expectBachelors</th>\n",
       "      <th>motherHS</th>\n",
       "      <th>motherBachelors</th>\n",
       "      <th>motherWork</th>\n",
       "      <th>fatherHS</th>\n",
       "      <th>fatherBachelors</th>\n",
       "      <th>...</th>\n",
       "      <th>englishAtHome</th>\n",
       "      <th>computerForSchoolwork</th>\n",
       "      <th>read30MinsADay</th>\n",
       "      <th>minutesPerWeekEnglish</th>\n",
       "      <th>studentsInEnglish</th>\n",
       "      <th>schoolHasLibrary</th>\n",
       "      <th>publicSchool</th>\n",
       "      <th>urban</th>\n",
       "      <th>schoolSize</th>\n",
       "      <th>readingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>355.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>385.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>522.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>406.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>453.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>509.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>444.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>539.0</td>\n",
       "      <td>476.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>551.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5233 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      grade  male   raceeth  preschool  expectBachelors  motherHS  \\\n",
       "0        10     0     White        1.0              0.0       1.0   \n",
       "1        10     1     White        0.0              0.0       1.0   \n",
       "2        10     0     White        1.0              0.0       1.0   \n",
       "3        10     0     White        1.0              0.0       1.0   \n",
       "4        10     0     White        1.0              1.0       1.0   \n",
       "...     ...   ...       ...        ...              ...       ...   \n",
       "3658      9     1     White        0.0              1.0       1.0   \n",
       "3659      9     1     White        0.0              0.0       1.0   \n",
       "3660     10     1  Hispanic        1.0              1.0       1.0   \n",
       "3661     11     1     Black        0.0              0.0       1.0   \n",
       "3662     10     0     White        0.0              1.0       1.0   \n",
       "\n",
       "      motherBachelors  motherWork  fatherHS  fatherBachelors  ...  \\\n",
       "0                 1.0         1.0       1.0              0.0  ...   \n",
       "1                 0.0         1.0       1.0              0.0  ...   \n",
       "2                 0.0         1.0       1.0              0.0  ...   \n",
       "3                 1.0         1.0       1.0              0.0  ...   \n",
       "4                 0.0         0.0       1.0              1.0  ...   \n",
       "...               ...         ...       ...              ...  ...   \n",
       "3658              NaN         0.0       1.0              1.0  ...   \n",
       "3659              0.0         1.0       1.0              0.0  ...   \n",
       "3660              0.0         1.0       1.0              0.0  ...   \n",
       "3661              0.0         NaN       NaN              0.0  ...   \n",
       "3662              0.0         1.0       1.0              0.0  ...   \n",
       "\n",
       "      englishAtHome  computerForSchoolwork  read30MinsADay  \\\n",
       "0               1.0                    1.0             0.0   \n",
       "1               1.0                    1.0             0.0   \n",
       "2               1.0                    1.0             0.0   \n",
       "3               1.0                    1.0             0.0   \n",
       "4               1.0                    1.0             0.0   \n",
       "...             ...                    ...             ...   \n",
       "3658            1.0                    1.0             0.0   \n",
       "3659            1.0                    0.0             1.0   \n",
       "3660            1.0                    1.0             0.0   \n",
       "3661            1.0                    1.0             0.0   \n",
       "3662            1.0                    1.0             1.0   \n",
       "\n",
       "      minutesPerWeekEnglish  studentsInEnglish  schoolHasLibrary  \\\n",
       "0                     240.0               30.0               1.0   \n",
       "1                     255.0                NaN               1.0   \n",
       "2                       NaN               30.0               1.0   \n",
       "3                     160.0               30.0               NaN   \n",
       "4                     240.0               30.0               1.0   \n",
       "...                     ...                ...               ...   \n",
       "3658                  250.0               20.0               1.0   \n",
       "3659                  450.0               16.0               1.0   \n",
       "3660                  225.0               16.0               1.0   \n",
       "3661                   54.0               36.0               1.0   \n",
       "3662                  235.0               25.0               1.0   \n",
       "\n",
       "      publicSchool  urban  schoolSize  readingScore  \n",
       "0                1      0       808.0        355.24  \n",
       "1                1      0       808.0        385.57  \n",
       "2                1      0       808.0        522.62  \n",
       "3                1      0       808.0        406.24  \n",
       "4                1      0       808.0        453.50  \n",
       "...            ...    ...         ...           ...  \n",
       "3658             1      0       421.0        509.99  \n",
       "3659             1      0      1317.0        444.90  \n",
       "3660             1      1       539.0        476.89  \n",
       "3661             1      1         NaN        363.61  \n",
       "3662             1      0       227.0        551.85  \n",
       "\n",
       "[5233 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate wine and wine1\n",
    "a=[stand_test,stand_test1]\n",
    "dataset = pd.concat(a)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "889ad73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade                      0\n",
       "male                       0\n",
       "raceeth                   48\n",
       "preschool                 77\n",
       "expectBachelors           85\n",
       "motherHS                 142\n",
       "motherBachelors          585\n",
       "motherWork               129\n",
       "fatherHS                 370\n",
       "fatherBachelors          857\n",
       "fatherWork               346\n",
       "selfBornUS                93\n",
       "motherBornUS              94\n",
       "fatherBornUS             171\n",
       "englishAtHome             98\n",
       "computerForSchoolwork     95\n",
       "read30MinsADay            55\n",
       "minutesPerWeekEnglish    289\n",
       "studentsInEnglish        363\n",
       "schoolHasLibrary         201\n",
       "publicSchool               0\n",
       "urban                      0\n",
       "schoolSize               231\n",
       "readingScore               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99d97ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5233 entries, 0 to 3662\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   grade                  5233 non-null   int64  \n",
      " 1   male                   5233 non-null   int64  \n",
      " 2   raceeth                5185 non-null   object \n",
      " 3   preschool              5156 non-null   float64\n",
      " 4   expectBachelors        5148 non-null   float64\n",
      " 5   motherHS               5091 non-null   float64\n",
      " 6   motherBachelors        4648 non-null   float64\n",
      " 7   motherWork             5104 non-null   float64\n",
      " 8   fatherHS               4863 non-null   float64\n",
      " 9   fatherBachelors        4376 non-null   float64\n",
      " 10  fatherWork             4887 non-null   float64\n",
      " 11  selfBornUS             5140 non-null   float64\n",
      " 12  motherBornUS           5139 non-null   float64\n",
      " 13  fatherBornUS           5062 non-null   float64\n",
      " 14  englishAtHome          5135 non-null   float64\n",
      " 15  computerForSchoolwork  5138 non-null   float64\n",
      " 16  read30MinsADay         5178 non-null   float64\n",
      " 17  minutesPerWeekEnglish  4944 non-null   float64\n",
      " 18  studentsInEnglish      4870 non-null   float64\n",
      " 19  schoolHasLibrary       5032 non-null   float64\n",
      " 20  publicSchool           5233 non-null   int64  \n",
      " 21  urban                  5233 non-null   int64  \n",
      " 22  schoolSize             5002 non-null   float64\n",
      " 23  readingScore           5233 non-null   float64\n",
      "dtypes: float64(19), int64(4), object(1)\n",
      "memory usage: 1022.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c07f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f8c75fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade                    0\n",
       "male                     0\n",
       "raceeth                  0\n",
       "preschool                0\n",
       "expectBachelors          0\n",
       "motherHS                 0\n",
       "motherBachelors          0\n",
       "motherWork               0\n",
       "fatherHS                 0\n",
       "fatherBachelors          0\n",
       "fatherWork               0\n",
       "selfBornUS               0\n",
       "motherBornUS             0\n",
       "fatherBornUS             0\n",
       "englishAtHome            0\n",
       "computerForSchoolwork    0\n",
       "read30MinsADay           0\n",
       "minutesPerWeekEnglish    0\n",
       "studentsInEnglish        0\n",
       "schoolHasLibrary         0\n",
       "publicSchool             0\n",
       "urban                    0\n",
       "schoolSize               0\n",
       "readingScore             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d8ffd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djbro\\AppData\\Local\\Temp\\ipykernel_14736\\2164675448.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['raceeth']= label_encoder.fit_transform(dataset['raceeth'])\n"
     ]
    }
   ],
   "source": [
    "#Import label encoder\n",
    "from sklearn import preprocessing\n",
    "  \n",
    "#label_encoder object knows how to understand word labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "#Encode labels in column Sex and Embarked\n",
    "dataset['raceeth']= label_encoder.fit_transform(dataset['raceeth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "810b1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3404 entries, 0 to 3662\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   grade                  3404 non-null   int64  \n",
      " 1   male                   3404 non-null   int64  \n",
      " 2   raceeth                3404 non-null   int32  \n",
      " 3   preschool              3404 non-null   float64\n",
      " 4   expectBachelors        3404 non-null   float64\n",
      " 5   motherHS               3404 non-null   float64\n",
      " 6   motherBachelors        3404 non-null   float64\n",
      " 7   motherWork             3404 non-null   float64\n",
      " 8   fatherHS               3404 non-null   float64\n",
      " 9   fatherBachelors        3404 non-null   float64\n",
      " 10  fatherWork             3404 non-null   float64\n",
      " 11  selfBornUS             3404 non-null   float64\n",
      " 12  motherBornUS           3404 non-null   float64\n",
      " 13  fatherBornUS           3404 non-null   float64\n",
      " 14  englishAtHome          3404 non-null   float64\n",
      " 15  computerForSchoolwork  3404 non-null   float64\n",
      " 16  read30MinsADay         3404 non-null   float64\n",
      " 17  minutesPerWeekEnglish  3404 non-null   float64\n",
      " 18  studentsInEnglish      3404 non-null   float64\n",
      " 19  schoolHasLibrary       3404 non-null   float64\n",
      " 20  publicSchool           3404 non-null   int64  \n",
      " 21  urban                  3404 non-null   int64  \n",
      " 22  schoolSize             3404 non-null   float64\n",
      " 23  readingScore           3404 non-null   float64\n",
      "dtypes: float64(19), int32(1), int64(4)\n",
      "memory usage: 651.5 KB\n",
      "None\n",
      "             grade         male      raceeth    preschool  expectBachelors  \\\n",
      "count  3404.000000  3404.000000  3404.000000  3404.000000      3404.000000   \n",
      "mean     10.126910     0.498531     4.685370     0.725911         0.827556   \n",
      "std       0.520284     0.500071     1.751875     0.446120         0.377822   \n",
      "min       8.000000     0.000000     0.000000     0.000000         0.000000   \n",
      "25%      10.000000     0.000000     3.000000     0.000000         1.000000   \n",
      "50%      10.000000     0.000000     6.000000     1.000000         1.000000   \n",
      "75%      10.000000     1.000000     6.000000     1.000000         1.000000   \n",
      "max      12.000000     1.000000     6.000000     1.000000         1.000000   \n",
      "\n",
      "          motherHS  motherBachelors   motherWork     fatherHS  \\\n",
      "count  3404.000000      3404.000000  3404.000000  3404.000000   \n",
      "mean      0.889542         0.354289     0.730905     0.867215   \n",
      "std       0.313506         0.478368     0.443555     0.339392   \n",
      "min       0.000000         0.000000     0.000000     0.000000   \n",
      "25%       1.000000         0.000000     0.000000     1.000000   \n",
      "50%       1.000000         0.000000     1.000000     1.000000   \n",
      "75%       1.000000         1.000000     1.000000     1.000000   \n",
      "max       1.000000         1.000000     1.000000     1.000000   \n",
      "\n",
      "       fatherBachelors  ...  englishAtHome  computerForSchoolwork  \\\n",
      "count      3404.000000  ...    3404.000000            3404.000000   \n",
      "mean          0.341069  ...       0.876616               0.917156   \n",
      "std           0.474138  ...       0.328926               0.275686   \n",
      "min           0.000000  ...       0.000000               0.000000   \n",
      "25%           0.000000  ...       1.000000               1.000000   \n",
      "50%           0.000000  ...       1.000000               1.000000   \n",
      "75%           1.000000  ...       1.000000               1.000000   \n",
      "max           1.000000  ...       1.000000               1.000000   \n",
      "\n",
      "       read30MinsADay  minutesPerWeekEnglish  studentsInEnglish  \\\n",
      "count     3404.000000            3404.000000        3404.000000   \n",
      "mean         0.299941             269.029377          24.591951   \n",
      "std          0.458299             141.631752           6.966783   \n",
      "min          0.000000               0.000000           1.000000   \n",
      "25%          0.000000             225.000000          20.000000   \n",
      "50%          0.000000             250.000000          25.000000   \n",
      "75%          1.000000             300.000000          30.000000   \n",
      "max          1.000000            2025.000000          90.000000   \n",
      "\n",
      "       schoolHasLibrary  publicSchool        urban   schoolSize  readingScore  \n",
      "count       3404.000000   3404.000000  3404.000000  3404.000000   3404.000000  \n",
      "mean           0.969741      0.916275     0.360165  1372.634841    518.515875  \n",
      "std            0.171323      0.277016     0.480118   855.541812     89.164390  \n",
      "min            0.000000      0.000000     0.000000   100.000000    242.640000  \n",
      "25%            1.000000      1.000000     0.000000   690.000000    457.120000  \n",
      "50%            1.000000      1.000000     0.000000  1233.000000    520.205000  \n",
      "75%            1.000000      1.000000     1.000000  1900.000000    581.980000  \n",
      "max            1.000000      1.000000     1.000000  6694.000000    772.460000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values\n",
    "print(dataset.info())\n",
    "\n",
    "# Checking for outliers\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "625879b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 3, 2, 4, 1, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.raceeth.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30d067fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>male</th>\n",
       "      <th>raceeth</th>\n",
       "      <th>preschool</th>\n",
       "      <th>expectBachelors</th>\n",
       "      <th>motherHS</th>\n",
       "      <th>motherBachelors</th>\n",
       "      <th>motherWork</th>\n",
       "      <th>fatherHS</th>\n",
       "      <th>fatherBachelors</th>\n",
       "      <th>...</th>\n",
       "      <th>englishAtHome</th>\n",
       "      <th>computerForSchoolwork</th>\n",
       "      <th>read30MinsADay</th>\n",
       "      <th>minutesPerWeekEnglish</th>\n",
       "      <th>studentsInEnglish</th>\n",
       "      <th>schoolHasLibrary</th>\n",
       "      <th>publicSchool</th>\n",
       "      <th>urban</th>\n",
       "      <th>schoolSize</th>\n",
       "      <th>readingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>355.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>453.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>405.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>665.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>604.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade  male  raceeth  preschool  expectBachelors  motherHS  \\\n",
       "0     10     0        6        1.0              0.0       1.0   \n",
       "4     10     0        6        1.0              1.0       1.0   \n",
       "6     10     0        0        1.0              0.0       1.0   \n",
       "7     10     0        6        1.0              0.0       1.0   \n",
       "8     11     0        6        0.0              0.0       1.0   \n",
       "\n",
       "   motherBachelors  motherWork  fatherHS  fatherBachelors  ...  englishAtHome  \\\n",
       "0              1.0         1.0       1.0              0.0  ...            1.0   \n",
       "4              0.0         0.0       1.0              1.0  ...            1.0   \n",
       "6              0.0         0.0       1.0              0.0  ...            1.0   \n",
       "7              0.0         1.0       1.0              0.0  ...            1.0   \n",
       "8              1.0         1.0       1.0              1.0  ...            1.0   \n",
       "\n",
       "   computerForSchoolwork  read30MinsADay  minutesPerWeekEnglish  \\\n",
       "0                    1.0             0.0                  240.0   \n",
       "4                    1.0             0.0                  240.0   \n",
       "6                    1.0             1.0                  240.0   \n",
       "7                    1.0             1.0                  270.0   \n",
       "8                    1.0             1.0                  270.0   \n",
       "\n",
       "   studentsInEnglish  schoolHasLibrary  publicSchool  urban  schoolSize  \\\n",
       "0               30.0               1.0             1      0       808.0   \n",
       "4               30.0               1.0             1      0       808.0   \n",
       "6               30.0               1.0             1      0       808.0   \n",
       "7               35.0               1.0             1      0       808.0   \n",
       "8               30.0               1.0             1      0       808.0   \n",
       "\n",
       "   readingScore  \n",
       "0        355.24  \n",
       "4        453.50  \n",
       "6        405.13  \n",
       "7        665.05  \n",
       "8        604.84  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6ffafe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grade', 'male', 'raceeth', 'preschool', 'expectBachelors', 'motherHS',\n",
       "       'motherBachelors', 'motherWork', 'fatherHS', 'fatherBachelors',\n",
       "       'fatherWork', 'selfBornUS', 'motherBornUS', 'fatherBornUS',\n",
       "       'englishAtHome', 'computerForSchoolwork', 'read30MinsADay',\n",
       "       'minutesPerWeekEnglish', 'studentsInEnglish', 'schoolHasLibrary',\n",
       "       'publicSchool', 'urban', 'schoolSize', 'readingScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d44b552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>male</th>\n",
       "      <th>raceeth</th>\n",
       "      <th>preschool</th>\n",
       "      <th>expectBachelors</th>\n",
       "      <th>motherHS</th>\n",
       "      <th>motherBachelors</th>\n",
       "      <th>motherWork</th>\n",
       "      <th>fatherHS</th>\n",
       "      <th>fatherBachelors</th>\n",
       "      <th>...</th>\n",
       "      <th>englishAtHome</th>\n",
       "      <th>computerForSchoolwork</th>\n",
       "      <th>read30MinsADay</th>\n",
       "      <th>minutesPerWeekEnglish</th>\n",
       "      <th>studentsInEnglish</th>\n",
       "      <th>schoolHasLibrary</th>\n",
       "      <th>publicSchool</th>\n",
       "      <th>urban</th>\n",
       "      <th>schoolSize</th>\n",
       "      <th>readingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088510</td>\n",
       "      <td>-0.023883</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.115848</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.035358</td>\n",
       "      <td>0.032151</td>\n",
       "      <td>0.055522</td>\n",
       "      <td>0.057963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009784</td>\n",
       "      <td>0.083564</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.054908</td>\n",
       "      <td>-0.026137</td>\n",
       "      <td>-0.048588</td>\n",
       "      <td>0.080475</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>0.222190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-0.088510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>-0.092327</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.052541</td>\n",
       "      <td>-0.015031</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006462</td>\n",
       "      <td>-0.017935</td>\n",
       "      <td>-0.200024</td>\n",
       "      <td>-0.004372</td>\n",
       "      <td>-0.036653</td>\n",
       "      <td>0.032066</td>\n",
       "      <td>-0.088922</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.120640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raceeth</th>\n",
       "      <td>-0.023883</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058449</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390556</td>\n",
       "      <td>0.086566</td>\n",
       "      <td>-0.008331</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>-0.070715</td>\n",
       "      <td>-0.011168</td>\n",
       "      <td>-0.048847</td>\n",
       "      <td>-0.285179</td>\n",
       "      <td>-0.197085</td>\n",
       "      <td>0.247034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preschool</th>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.058449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103052</td>\n",
       "      <td>0.138550</td>\n",
       "      <td>0.167373</td>\n",
       "      <td>0.083065</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.161456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119919</td>\n",
       "      <td>0.116375</td>\n",
       "      <td>-0.013158</td>\n",
       "      <td>-0.019020</td>\n",
       "      <td>-0.030417</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>-0.100144</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>-0.012268</td>\n",
       "      <td>0.075072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectBachelors</th>\n",
       "      <td>0.115848</td>\n",
       "      <td>-0.092327</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>0.103052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.119481</td>\n",
       "      <td>0.177169</td>\n",
       "      <td>0.071965</td>\n",
       "      <td>0.160543</td>\n",
       "      <td>0.220153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.153392</td>\n",
       "      <td>0.113816</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.032860</td>\n",
       "      <td>-0.109911</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>0.343326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherHS</th>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.138550</td>\n",
       "      <td>0.119481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.160225</td>\n",
       "      <td>0.511132</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403534</td>\n",
       "      <td>0.162692</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>-0.044187</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>-0.076067</td>\n",
       "      <td>-0.108504</td>\n",
       "      <td>-0.081655</td>\n",
       "      <td>0.152614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherBachelors</th>\n",
       "      <td>0.035358</td>\n",
       "      <td>0.052541</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.167373</td>\n",
       "      <td>0.177169</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132301</td>\n",
       "      <td>0.202969</td>\n",
       "      <td>0.550203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158373</td>\n",
       "      <td>0.137949</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>-0.041785</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>-0.186335</td>\n",
       "      <td>-0.023489</td>\n",
       "      <td>-0.003737</td>\n",
       "      <td>0.228640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherWork</th>\n",
       "      <td>0.032151</td>\n",
       "      <td>-0.015031</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.083065</td>\n",
       "      <td>0.071965</td>\n",
       "      <td>0.160225</td>\n",
       "      <td>0.132301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136922</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>-0.032170</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>-0.018142</td>\n",
       "      <td>-0.010506</td>\n",
       "      <td>-0.027963</td>\n",
       "      <td>-0.022201</td>\n",
       "      <td>-0.054051</td>\n",
       "      <td>0.039399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatherHS</th>\n",
       "      <td>0.055522</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.160543</td>\n",
       "      <td>0.511132</td>\n",
       "      <td>0.202969</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361234</td>\n",
       "      <td>0.165056</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>-0.023668</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>-0.083902</td>\n",
       "      <td>-0.097754</td>\n",
       "      <td>-0.080720</td>\n",
       "      <td>0.195039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatherBachelors</th>\n",
       "      <td>0.057963</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.161456</td>\n",
       "      <td>0.220153</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.550203</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.272391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130482</td>\n",
       "      <td>0.160024</td>\n",
       "      <td>0.048371</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>-0.033205</td>\n",
       "      <td>-0.003147</td>\n",
       "      <td>-0.191952</td>\n",
       "      <td>-0.009231</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>0.278953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatherWork</th>\n",
       "      <td>0.016955</td>\n",
       "      <td>0.039694</td>\n",
       "      <td>0.096688</td>\n",
       "      <td>0.059649</td>\n",
       "      <td>0.033112</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.076205</td>\n",
       "      <td>0.058982</td>\n",
       "      <td>0.084958</td>\n",
       "      <td>0.111191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.097385</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.009367</td>\n",
       "      <td>-0.009344</td>\n",
       "      <td>-0.021930</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>-0.016588</td>\n",
       "      <td>0.075384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfBornUS</th>\n",
       "      <td>-0.028336</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.244736</td>\n",
       "      <td>0.089791</td>\n",
       "      <td>-0.003177</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>0.167695</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492622</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>-0.004058</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>-0.020030</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>-0.041287</td>\n",
       "      <td>-0.118263</td>\n",
       "      <td>-0.130285</td>\n",
       "      <td>0.038674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherBornUS</th>\n",
       "      <td>-0.073732</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.497586</td>\n",
       "      <td>0.093709</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>0.375398</td>\n",
       "      <td>0.133455</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>0.316447</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664986</td>\n",
       "      <td>-0.002306</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>-0.094802</td>\n",
       "      <td>-0.013504</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>-0.265154</td>\n",
       "      <td>-0.244064</td>\n",
       "      <td>0.073225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatherBornUS</th>\n",
       "      <td>-0.069322</td>\n",
       "      <td>0.011960</td>\n",
       "      <td>0.482441</td>\n",
       "      <td>0.093035</td>\n",
       "      <td>-0.011533</td>\n",
       "      <td>0.346970</td>\n",
       "      <td>0.108897</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.340230</td>\n",
       "      <td>0.077131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640793</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>-0.088333</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>-0.280591</td>\n",
       "      <td>-0.249276</td>\n",
       "      <td>0.078642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>englishAtHome</th>\n",
       "      <td>-0.009784</td>\n",
       "      <td>-0.006462</td>\n",
       "      <td>0.390556</td>\n",
       "      <td>0.119919</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.403534</td>\n",
       "      <td>0.158373</td>\n",
       "      <td>0.136922</td>\n",
       "      <td>0.361234</td>\n",
       "      <td>0.130482</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065478</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.019339</td>\n",
       "      <td>-0.042456</td>\n",
       "      <td>-0.204183</td>\n",
       "      <td>-0.207495</td>\n",
       "      <td>0.127545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computerForSchoolwork</th>\n",
       "      <td>0.083564</td>\n",
       "      <td>-0.017935</td>\n",
       "      <td>0.086566</td>\n",
       "      <td>0.116375</td>\n",
       "      <td>0.153392</td>\n",
       "      <td>0.162692</td>\n",
       "      <td>0.137949</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.165056</td>\n",
       "      <td>0.160024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>-0.071610</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.066658</td>\n",
       "      <td>0.178640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read30MinsADay</th>\n",
       "      <td>0.041193</td>\n",
       "      <td>-0.200024</td>\n",
       "      <td>-0.008331</td>\n",
       "      <td>-0.013158</td>\n",
       "      <td>0.113816</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>-0.032170</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.048371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>-0.015736</td>\n",
       "      <td>0.224203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutesPerWeekEnglish</th>\n",
       "      <td>0.038795</td>\n",
       "      <td>-0.004372</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>-0.019020</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036647</td>\n",
       "      <td>-0.011468</td>\n",
       "      <td>0.050320</td>\n",
       "      <td>-0.043171</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.040550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studentsInEnglish</th>\n",
       "      <td>0.054908</td>\n",
       "      <td>-0.036653</td>\n",
       "      <td>-0.070715</td>\n",
       "      <td>-0.030417</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>-0.044187</td>\n",
       "      <td>-0.041785</td>\n",
       "      <td>-0.018142</td>\n",
       "      <td>-0.023668</td>\n",
       "      <td>-0.033205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.036647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068191</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.157105</td>\n",
       "      <td>0.277874</td>\n",
       "      <td>0.010996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolHasLibrary</th>\n",
       "      <td>-0.026137</td>\n",
       "      <td>0.032066</td>\n",
       "      <td>-0.011168</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.032860</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>-0.010506</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>-0.003147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019339</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>-0.011468</td>\n",
       "      <td>0.068191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>-0.131837</td>\n",
       "      <td>0.047331</td>\n",
       "      <td>-0.001367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicSchool</th>\n",
       "      <td>-0.048588</td>\n",
       "      <td>-0.088922</td>\n",
       "      <td>-0.048847</td>\n",
       "      <td>-0.100144</td>\n",
       "      <td>-0.109911</td>\n",
       "      <td>-0.076067</td>\n",
       "      <td>-0.186335</td>\n",
       "      <td>-0.027963</td>\n",
       "      <td>-0.083902</td>\n",
       "      <td>-0.191952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042456</td>\n",
       "      <td>-0.071610</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.050320</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.314523</td>\n",
       "      <td>0.258317</td>\n",
       "      <td>-0.118651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urban</th>\n",
       "      <td>0.080475</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>-0.285179</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-0.108504</td>\n",
       "      <td>-0.023489</td>\n",
       "      <td>-0.022201</td>\n",
       "      <td>-0.097754</td>\n",
       "      <td>-0.009231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204183</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>-0.043171</td>\n",
       "      <td>0.157105</td>\n",
       "      <td>-0.131837</td>\n",
       "      <td>-0.314523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321948</td>\n",
       "      <td>-0.013092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolSize</th>\n",
       "      <td>0.068044</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.197085</td>\n",
       "      <td>-0.012268</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>-0.081655</td>\n",
       "      <td>-0.003737</td>\n",
       "      <td>-0.054051</td>\n",
       "      <td>-0.080720</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207495</td>\n",
       "      <td>0.066658</td>\n",
       "      <td>-0.015736</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.277874</td>\n",
       "      <td>0.047331</td>\n",
       "      <td>0.258317</td>\n",
       "      <td>0.321948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readingScore</th>\n",
       "      <td>0.222190</td>\n",
       "      <td>-0.120640</td>\n",
       "      <td>0.247034</td>\n",
       "      <td>0.075072</td>\n",
       "      <td>0.343326</td>\n",
       "      <td>0.152614</td>\n",
       "      <td>0.228640</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>0.195039</td>\n",
       "      <td>0.278953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127545</td>\n",
       "      <td>0.178640</td>\n",
       "      <td>0.224203</td>\n",
       "      <td>0.040550</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>-0.118651</td>\n",
       "      <td>-0.013092</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          grade      male   raceeth  preschool  \\\n",
       "grade                  1.000000 -0.088510 -0.023883   0.008111   \n",
       "male                  -0.088510  1.000000  0.020437   0.012026   \n",
       "raceeth               -0.023883  0.020437  1.000000   0.058449   \n",
       "preschool              0.008111  0.012026  0.058449   1.000000   \n",
       "expectBachelors        0.115848 -0.092327  0.033880   0.103052   \n",
       "motherHS               0.015706  0.030829  0.227232   0.138550   \n",
       "motherBachelors        0.035358  0.052541  0.159000   0.167373   \n",
       "motherWork             0.032151 -0.015031  0.069507   0.083065   \n",
       "fatherHS               0.055522  0.028285  0.229714   0.134133   \n",
       "fatherBachelors        0.057963  0.058505  0.170622   0.161456   \n",
       "fatherWork             0.016955  0.039694  0.096688   0.059649   \n",
       "selfBornUS            -0.028336  0.026843  0.244736   0.089791   \n",
       "motherBornUS          -0.073732  0.000600  0.497586   0.093709   \n",
       "fatherBornUS          -0.069322  0.011960  0.482441   0.093035   \n",
       "englishAtHome         -0.009784 -0.006462  0.390556   0.119919   \n",
       "computerForSchoolwork  0.083564 -0.017935  0.086566   0.116375   \n",
       "read30MinsADay         0.041193 -0.200024 -0.008331  -0.013158   \n",
       "minutesPerWeekEnglish  0.038795 -0.004372  0.017388  -0.019020   \n",
       "studentsInEnglish      0.054908 -0.036653 -0.070715  -0.030417   \n",
       "schoolHasLibrary      -0.026137  0.032066 -0.011168   0.006801   \n",
       "publicSchool          -0.048588 -0.088922 -0.048847  -0.100144   \n",
       "urban                  0.080475  0.025459 -0.285179  -0.015045   \n",
       "schoolSize             0.068044 -0.003000 -0.197085  -0.012268   \n",
       "readingScore           0.222190 -0.120640  0.247034   0.075072   \n",
       "\n",
       "                       expectBachelors  motherHS  motherBachelors  motherWork  \\\n",
       "grade                         0.115848  0.015706         0.035358    0.032151   \n",
       "male                         -0.092327  0.030829         0.052541   -0.015031   \n",
       "raceeth                       0.033880  0.227232         0.159000    0.069507   \n",
       "preschool                     0.103052  0.138550         0.167373    0.083065   \n",
       "expectBachelors               1.000000  0.119481         0.177169    0.071965   \n",
       "motherHS                      0.119481  1.000000         0.243386    0.160225   \n",
       "motherBachelors               0.177169  0.243386         1.000000    0.132301   \n",
       "motherWork                    0.071965  0.160225         0.132301    1.000000   \n",
       "fatherHS                      0.160543  0.511132         0.202969    0.121747   \n",
       "fatherBachelors               0.220153  0.229800         0.550203    0.052286   \n",
       "fatherWork                    0.033112  0.004112         0.076205    0.058982   \n",
       "selfBornUS                   -0.003177  0.204745         0.034493    0.080410   \n",
       "motherBornUS                 -0.001411  0.375398         0.133455    0.108209   \n",
       "fatherBornUS                 -0.011533  0.346970         0.108897    0.091506   \n",
       "englishAtHome                 0.051012  0.403534         0.158373    0.136922   \n",
       "computerForSchoolwork         0.153392  0.162692         0.137949    0.084386   \n",
       "read30MinsADay                0.113816  0.011817         0.029851   -0.032170   \n",
       "minutesPerWeekEnglish         0.012247  0.009788         0.015066    0.023477   \n",
       "studentsInEnglish             0.032652 -0.044187        -0.041785   -0.018142   \n",
       "schoolHasLibrary              0.032860  0.008879        -0.005408   -0.010506   \n",
       "publicSchool                 -0.109911 -0.076067        -0.186335   -0.027963   \n",
       "urban                         0.024974 -0.108504        -0.023489   -0.022201   \n",
       "schoolSize                    0.038534 -0.081655        -0.003737   -0.054051   \n",
       "readingScore                  0.343326  0.152614         0.228640    0.039399   \n",
       "\n",
       "                       fatherHS  fatherBachelors  ...  englishAtHome  \\\n",
       "grade                  0.055522         0.057963  ...      -0.009784   \n",
       "male                   0.028285         0.058505  ...      -0.006462   \n",
       "raceeth                0.229714         0.170622  ...       0.390556   \n",
       "preschool              0.134133         0.161456  ...       0.119919   \n",
       "expectBachelors        0.160543         0.220153  ...       0.051012   \n",
       "motherHS               0.511132         0.229800  ...       0.403534   \n",
       "motherBachelors        0.202969         0.550203  ...       0.158373   \n",
       "motherWork             0.121747         0.052286  ...       0.136922   \n",
       "fatherHS               1.000000         0.272391  ...       0.361234   \n",
       "fatherBachelors        0.272391         1.000000  ...       0.130482   \n",
       "fatherWork             0.084958         0.111191  ...       0.010588   \n",
       "selfBornUS             0.167695         0.010144  ...       0.492622   \n",
       "motherBornUS           0.316447         0.070312  ...       0.664986   \n",
       "fatherBornUS           0.340230         0.077131  ...       0.640793   \n",
       "englishAtHome          0.361234         0.130482  ...       1.000000   \n",
       "computerForSchoolwork  0.165056         0.160024  ...       0.065478   \n",
       "read30MinsADay         0.038868         0.048371  ...       0.013597   \n",
       "minutesPerWeekEnglish  0.020090         0.005093  ...      -0.000925   \n",
       "studentsInEnglish     -0.023668        -0.033205  ...      -0.067501   \n",
       "schoolHasLibrary       0.016795        -0.003147  ...      -0.019339   \n",
       "publicSchool          -0.083902        -0.191952  ...      -0.042456   \n",
       "urban                 -0.097754        -0.009231  ...      -0.204183   \n",
       "schoolSize            -0.080720         0.020604  ...      -0.207495   \n",
       "readingScore           0.195039         0.278953  ...       0.127545   \n",
       "\n",
       "                       computerForSchoolwork  read30MinsADay  \\\n",
       "grade                               0.083564        0.041193   \n",
       "male                               -0.017935       -0.200024   \n",
       "raceeth                             0.086566       -0.008331   \n",
       "preschool                           0.116375       -0.013158   \n",
       "expectBachelors                     0.153392        0.113816   \n",
       "motherHS                            0.162692        0.011817   \n",
       "motherBachelors                     0.137949        0.029851   \n",
       "motherWork                          0.084386       -0.032170   \n",
       "fatherHS                            0.165056        0.038868   \n",
       "fatherBachelors                     0.160024        0.048371   \n",
       "fatherWork                          0.097385        0.016160   \n",
       "selfBornUS                          0.005363       -0.004058   \n",
       "motherBornUS                       -0.002306        0.014735   \n",
       "fatherBornUS                        0.003734        0.018401   \n",
       "englishAtHome                       0.065478        0.013597   \n",
       "computerForSchoolwork               1.000000       -0.019575   \n",
       "read30MinsADay                     -0.019575        1.000000   \n",
       "minutesPerWeekEnglish               0.001869        0.026950   \n",
       "studentsInEnglish                   0.041146        0.006591   \n",
       "schoolHasLibrary                   -0.003316        0.007088   \n",
       "publicSchool                       -0.071610        0.010377   \n",
       "urban                               0.043440        0.020396   \n",
       "schoolSize                          0.066658       -0.015736   \n",
       "readingScore                        0.178640        0.224203   \n",
       "\n",
       "                       minutesPerWeekEnglish  studentsInEnglish  \\\n",
       "grade                               0.038795           0.054908   \n",
       "male                               -0.004372          -0.036653   \n",
       "raceeth                             0.017388          -0.070715   \n",
       "preschool                          -0.019020          -0.030417   \n",
       "expectBachelors                     0.012247           0.032652   \n",
       "motherHS                            0.009788          -0.044187   \n",
       "motherBachelors                     0.015066          -0.041785   \n",
       "motherWork                          0.023477          -0.018142   \n",
       "fatherHS                            0.020090          -0.023668   \n",
       "fatherBachelors                     0.005093          -0.033205   \n",
       "fatherWork                          0.006298          -0.009367   \n",
       "selfBornUS                         -0.007338          -0.020030   \n",
       "motherBornUS                        0.013732          -0.094802   \n",
       "fatherBornUS                        0.006483          -0.088333   \n",
       "englishAtHome                      -0.000925          -0.067501   \n",
       "computerForSchoolwork               0.001869           0.041146   \n",
       "read30MinsADay                      0.026950           0.006591   \n",
       "minutesPerWeekEnglish               1.000000           0.036647   \n",
       "studentsInEnglish                   0.036647           1.000000   \n",
       "schoolHasLibrary                   -0.011468           0.068191   \n",
       "publicSchool                        0.050320           0.103039   \n",
       "urban                              -0.043171           0.157105   \n",
       "schoolSize                          0.009704           0.277874   \n",
       "readingScore                        0.040550           0.010996   \n",
       "\n",
       "                       schoolHasLibrary  publicSchool     urban  schoolSize  \\\n",
       "grade                         -0.026137     -0.048588  0.080475    0.068044   \n",
       "male                           0.032066     -0.088922  0.025459   -0.003000   \n",
       "raceeth                       -0.011168     -0.048847 -0.285179   -0.197085   \n",
       "preschool                      0.006801     -0.100144 -0.015045   -0.012268   \n",
       "expectBachelors                0.032860     -0.109911  0.024974    0.038534   \n",
       "motherHS                       0.008879     -0.076067 -0.108504   -0.081655   \n",
       "motherBachelors               -0.005408     -0.186335 -0.023489   -0.003737   \n",
       "motherWork                    -0.010506     -0.027963 -0.022201   -0.054051   \n",
       "fatherHS                       0.016795     -0.083902 -0.097754   -0.080720   \n",
       "fatherBachelors               -0.003147     -0.191952 -0.009231    0.020604   \n",
       "fatherWork                    -0.009344     -0.021930 -0.012935   -0.016588   \n",
       "selfBornUS                    -0.021531     -0.041287 -0.118263   -0.130285   \n",
       "motherBornUS                  -0.013504      0.016658 -0.265154   -0.244064   \n",
       "fatherBornUS                  -0.018608      0.027711 -0.280591   -0.249276   \n",
       "englishAtHome                 -0.019339     -0.042456 -0.204183   -0.207495   \n",
       "computerForSchoolwork         -0.003316     -0.071610  0.043440    0.066658   \n",
       "read30MinsADay                 0.007088      0.010377  0.020396   -0.015736   \n",
       "minutesPerWeekEnglish         -0.011468      0.050320 -0.043171    0.009704   \n",
       "studentsInEnglish              0.068191      0.103039  0.157105    0.277874   \n",
       "schoolHasLibrary               1.000000      0.064248 -0.131837    0.047331   \n",
       "publicSchool                   0.064248      1.000000 -0.314523    0.258317   \n",
       "urban                         -0.131837     -0.314523  1.000000    0.321948   \n",
       "schoolSize                     0.047331      0.258317  0.321948    1.000000   \n",
       "readingScore                  -0.001367     -0.118651 -0.013092    0.030228   \n",
       "\n",
       "                       readingScore  \n",
       "grade                      0.222190  \n",
       "male                      -0.120640  \n",
       "raceeth                    0.247034  \n",
       "preschool                  0.075072  \n",
       "expectBachelors            0.343326  \n",
       "motherHS                   0.152614  \n",
       "motherBachelors            0.228640  \n",
       "motherWork                 0.039399  \n",
       "fatherHS                   0.195039  \n",
       "fatherBachelors            0.278953  \n",
       "fatherWork                 0.075384  \n",
       "selfBornUS                 0.038674  \n",
       "motherBornUS               0.073225  \n",
       "fatherBornUS               0.078642  \n",
       "englishAtHome              0.127545  \n",
       "computerForSchoolwork      0.178640  \n",
       "read30MinsADay             0.224203  \n",
       "minutesPerWeekEnglish      0.040550  \n",
       "studentsInEnglish          0.010996  \n",
       "schoolHasLibrary          -0.001367  \n",
       "publicSchool              -0.118651  \n",
       "urban                     -0.013092  \n",
       "schoolSize                 0.030228  \n",
       "readingScore               1.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45f8eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify random seed so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(dataset, train_size = 0.7, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cddb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-scaling the Features\n",
    "#We can see that all the columns have \n",
    "#smaller integer values in the dataset \n",
    "#except the area column. So it is important to\n",
    "#re-scale the variables so that they all have a comparable scale. \n",
    "#If we don’t have relative scales, then some of the regression model \n",
    "#coefficients will be of different units compared to the other coefficients.\n",
    "\n",
    "#To do that, we use the MinMax scaling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce9f268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>male</th>\n",
       "      <th>raceeth</th>\n",
       "      <th>preschool</th>\n",
       "      <th>expectBachelors</th>\n",
       "      <th>motherHS</th>\n",
       "      <th>motherBachelors</th>\n",
       "      <th>motherWork</th>\n",
       "      <th>fatherHS</th>\n",
       "      <th>fatherBachelors</th>\n",
       "      <th>...</th>\n",
       "      <th>englishAtHome</th>\n",
       "      <th>computerForSchoolwork</th>\n",
       "      <th>read30MinsADay</th>\n",
       "      <th>minutesPerWeekEnglish</th>\n",
       "      <th>studentsInEnglish</th>\n",
       "      <th>schoolHasLibrary</th>\n",
       "      <th>publicSchool</th>\n",
       "      <th>urban</th>\n",
       "      <th>schoolSize</th>\n",
       "      <th>readingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195177</td>\n",
       "      <td>0.443188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195177</td>\n",
       "      <td>0.206674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288747</td>\n",
       "      <td>0.602054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100394</td>\n",
       "      <td>0.418218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.400060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181225</td>\n",
       "      <td>0.413140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189111</td>\n",
       "      <td>0.427145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143464</td>\n",
       "      <td>0.723057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168638</td>\n",
       "      <td>0.587841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179167</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174401</td>\n",
       "      <td>0.285210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2382 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      grade  male   raceeth  preschool  expectBachelors  motherHS  \\\n",
       "1938   0.50     1  0.333333        1.0              1.0       1.0   \n",
       "611    0.25     0  1.000000        0.0              1.0       0.0   \n",
       "48     0.50     0  0.166667        1.0              1.0       1.0   \n",
       "1169   0.50     1  0.333333        1.0              1.0       1.0   \n",
       "745    0.50     1  1.000000        1.0              1.0       1.0   \n",
       "...     ...   ...       ...        ...              ...       ...   \n",
       "1309   0.75     0  0.333333        0.0              1.0       0.0   \n",
       "3439   0.25     1  0.500000        1.0              1.0       1.0   \n",
       "1017   0.50     0  0.500000        1.0              1.0       0.0   \n",
       "2450   0.50     1  1.000000        1.0              1.0       1.0   \n",
       "2631   0.50     1  0.666667        1.0              0.0       1.0   \n",
       "\n",
       "      motherBachelors  motherWork  fatherHS  fatherBachelors  ...  \\\n",
       "1938              0.0         1.0       1.0              0.0  ...   \n",
       "611               1.0         0.0       1.0              0.0  ...   \n",
       "48                0.0         1.0       1.0              0.0  ...   \n",
       "1169              1.0         1.0       1.0              0.0  ...   \n",
       "745               0.0         1.0       1.0              0.0  ...   \n",
       "...               ...         ...       ...              ...  ...   \n",
       "1309              0.0         0.0       1.0              0.0  ...   \n",
       "3439              0.0         1.0       1.0              0.0  ...   \n",
       "1017              0.0         0.0       0.0              0.0  ...   \n",
       "2450              1.0         1.0       1.0              1.0  ...   \n",
       "2631              1.0         1.0       1.0              0.0  ...   \n",
       "\n",
       "      englishAtHome  computerForSchoolwork  read30MinsADay  \\\n",
       "1938            1.0                    1.0             1.0   \n",
       "611             1.0                    1.0             0.0   \n",
       "48              1.0                    1.0             0.0   \n",
       "1169            1.0                    1.0             0.0   \n",
       "745             1.0                    1.0             0.0   \n",
       "...             ...                    ...             ...   \n",
       "1309            1.0                    1.0             0.0   \n",
       "3439            1.0                    1.0             0.0   \n",
       "1017            1.0                    1.0             1.0   \n",
       "2450            1.0                    1.0             0.0   \n",
       "2631            1.0                    1.0             0.0   \n",
       "\n",
       "      minutesPerWeekEnglish  studentsInEnglish  schoolHasLibrary  \\\n",
       "1938               0.053571           0.256757               1.0   \n",
       "611                0.238095           0.337838               1.0   \n",
       "48                 0.148810           0.310811               1.0   \n",
       "1169               0.148810           0.297297               1.0   \n",
       "745                0.133929           0.189189               1.0   \n",
       "...                     ...                ...               ...   \n",
       "1309               0.208333           0.121622               1.0   \n",
       "3439               0.178571           0.391892               1.0   \n",
       "1017               0.207143           0.337838               1.0   \n",
       "2450               0.095238           0.256757               1.0   \n",
       "2631               0.179167           0.216216               1.0   \n",
       "\n",
       "      publicSchool  urban  schoolSize  readingScore  \n",
       "1938             1      0    0.195177      0.443188  \n",
       "611              1      0    0.195177      0.206674  \n",
       "48               1      1    0.288747      0.602054  \n",
       "1169             1      0    0.100394      0.418218  \n",
       "745              1      0    0.040340      0.400060  \n",
       "...            ...    ...         ...           ...  \n",
       "1309             1      0    0.181225      0.413140  \n",
       "3439             1      0    0.189111      0.427145  \n",
       "1017             1      1    0.143464      0.723057  \n",
       "2450             0      1    0.168638      0.587841  \n",
       "2631             1      0    0.174401      0.285210  \n",
       "\n",
       "[2382 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Applying scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
    "num_vars = ['minutesPerWeekEnglish', 'studentsInEnglish', 'schoolSize', 'readingScore','grade','raceeth']\n",
    "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b3dab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the training data set into X and Y\n",
    "y_train = df_train.pop('readingScore')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a154854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>readingScore</td>   <th>  R-squared:         </th> <td>   0.290</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.283</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.94</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 24 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>9.41e-157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:49:20</td>     <th>  Log-Likelihood:    </th> <td>  1276.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2382</td>      <th>  AIC:               </th> <td>  -2505.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2358</td>      <th>  BIC:               </th> <td>  -2367.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                 <td>    0.1484</td> <td>    0.032</td> <td>    4.575</td> <td> 0.000</td> <td>    0.085</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>                 <td>    0.2120</td> <td>    0.023</td> <td>    9.146</td> <td> 0.000</td> <td>    0.167</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>                  <td>   -0.0206</td> <td>    0.006</td> <td>   -3.416</td> <td> 0.001</td> <td>   -0.032</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raceeth</th>               <td>    0.1335</td> <td>    0.012</td> <td>   10.883</td> <td> 0.000</td> <td>    0.109</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>preschool</th>             <td>   -0.0009</td> <td>    0.007</td> <td>   -0.136</td> <td> 0.892</td> <td>   -0.014</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expectBachelors</th>       <td>    0.0954</td> <td>    0.008</td> <td>   11.520</td> <td> 0.000</td> <td>    0.079</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motherHS</th>              <td>    0.0103</td> <td>    0.012</td> <td>    0.873</td> <td> 0.383</td> <td>   -0.013</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motherBachelors</th>       <td>    0.0213</td> <td>    0.008</td> <td>    2.820</td> <td> 0.005</td> <td>    0.006</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motherWork</th>            <td>    0.0009</td> <td>    0.007</td> <td>    0.126</td> <td> 0.900</td> <td>   -0.013</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fatherHS</th>              <td>    0.0213</td> <td>    0.011</td> <td>    1.998</td> <td> 0.046</td> <td>    0.000</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fatherBachelors</th>       <td>    0.0427</td> <td>    0.008</td> <td>    5.519</td> <td> 0.000</td> <td>    0.028</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fatherWork</th>            <td>    0.0044</td> <td>    0.008</td> <td>    0.517</td> <td> 0.605</td> <td>   -0.012</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>selfBornUS</th>            <td>   -0.0001</td> <td>    0.013</td> <td>   -0.008</td> <td> 0.994</td> <td>   -0.026</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>motherBornUS</th>          <td>   -0.0328</td> <td>    0.013</td> <td>   -2.595</td> <td> 0.010</td> <td>   -0.058</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fatherBornUS</th>          <td>    0.0110</td> <td>    0.012</td> <td>    0.903</td> <td> 0.366</td> <td>   -0.013</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>englishAtHome</th>         <td>    0.0076</td> <td>    0.013</td> <td>    0.580</td> <td> 0.562</td> <td>   -0.018</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerForSchoolwork</th> <td>    0.0353</td> <td>    0.011</td> <td>    3.198</td> <td> 0.001</td> <td>    0.014</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>read30MinsADay</th>        <td>    0.0643</td> <td>    0.007</td> <td>    9.781</td> <td> 0.000</td> <td>    0.051</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minutesPerWeekEnglish</th> <td>    0.0443</td> <td>    0.036</td> <td>    1.229</td> <td> 0.219</td> <td>   -0.026</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studentsInEnglish</th>     <td>   -0.0050</td> <td>    0.034</td> <td>   -0.148</td> <td> 0.882</td> <td>   -0.072</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>schoolHasLibrary</th>      <td>    0.0047</td> <td>    0.017</td> <td>    0.278</td> <td> 0.781</td> <td>   -0.028</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publicSchool</th>          <td>   -0.0369</td> <td>    0.013</td> <td>   -2.918</td> <td> 0.004</td> <td>   -0.062</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban</th>                 <td>-2.712e-05</td> <td>    0.008</td> <td>   -0.003</td> <td> 0.997</td> <td>   -0.015</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>schoolSize</th>            <td>    0.0787</td> <td>    0.028</td> <td>    2.802</td> <td> 0.005</td> <td>    0.024</td> <td>    0.134</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.001</td> <th>  Durbin-Watson:     </th> <td>   1.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.368</td> <th>  Jarque-Bera (JB):  </th> <td>   1.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.067</td> <th>  Prob(JB):          </th> <td>   0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.041</td> <th>  Cond. No.          </th> <td>    47.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           readingScore   R-squared:                       0.290\n",
       "Model:                            OLS   Adj. R-squared:                  0.283\n",
       "Method:                 Least Squares   F-statistic:                     41.94\n",
       "Date:                Sat, 24 Dec 2022   Prob (F-statistic):          9.41e-157\n",
       "Time:                        13:49:20   Log-Likelihood:                 1276.6\n",
       "No. Observations:                2382   AIC:                            -2505.\n",
       "Df Residuals:                    2358   BIC:                            -2367.\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "const                     0.1484      0.032      4.575      0.000       0.085       0.212\n",
       "grade                     0.2120      0.023      9.146      0.000       0.167       0.257\n",
       "male                     -0.0206      0.006     -3.416      0.001      -0.032      -0.009\n",
       "raceeth                   0.1335      0.012     10.883      0.000       0.109       0.158\n",
       "preschool                -0.0009      0.007     -0.136      0.892      -0.014       0.012\n",
       "expectBachelors           0.0954      0.008     11.520      0.000       0.079       0.112\n",
       "motherHS                  0.0103      0.012      0.873      0.383      -0.013       0.034\n",
       "motherBachelors           0.0213      0.008      2.820      0.005       0.006       0.036\n",
       "motherWork                0.0009      0.007      0.126      0.900      -0.013       0.014\n",
       "fatherHS                  0.0213      0.011      1.998      0.046       0.000       0.042\n",
       "fatherBachelors           0.0427      0.008      5.519      0.000       0.028       0.058\n",
       "fatherWork                0.0044      0.008      0.517      0.605      -0.012       0.021\n",
       "selfBornUS               -0.0001      0.013     -0.008      0.994      -0.026       0.026\n",
       "motherBornUS             -0.0328      0.013     -2.595      0.010      -0.058      -0.008\n",
       "fatherBornUS              0.0110      0.012      0.903      0.366      -0.013       0.035\n",
       "englishAtHome             0.0076      0.013      0.580      0.562      -0.018       0.033\n",
       "computerForSchoolwork     0.0353      0.011      3.198      0.001       0.014       0.057\n",
       "read30MinsADay            0.0643      0.007      9.781      0.000       0.051       0.077\n",
       "minutesPerWeekEnglish     0.0443      0.036      1.229      0.219      -0.026       0.115\n",
       "studentsInEnglish        -0.0050      0.034     -0.148      0.882      -0.072       0.062\n",
       "schoolHasLibrary          0.0047      0.017      0.278      0.781      -0.028       0.038\n",
       "publicSchool             -0.0369      0.013     -2.918      0.004      -0.062      -0.012\n",
       "urban                 -2.712e-05      0.008     -0.003      0.997      -0.015       0.015\n",
       "schoolSize                0.0787      0.028      2.802      0.005       0.024       0.134\n",
       "==============================================================================\n",
       "Omnibus:                        2.001   Durbin-Watson:                   1.989\n",
       "Prob(Omnibus):                  0.368   Jarque-Bera (JB):                1.934\n",
       "Skew:                          -0.067   Prob(JB):                        0.380\n",
       "Kurtosis:                       3.041   Cond. No.                         47.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a linear model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "\n",
    "lr_1 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "lr_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bb1b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination (RFE)\n",
    "#RFE is an automatic process where we don’t need to select \n",
    "#variables manually. We follow the same steps we have done earlier \n",
    "#until Re-scaling the features and dividing the data into X and Y.\n",
    "\n",
    "#We will use the LinearRegression function from sklearn \n",
    "#for RFE (which is a utility from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "792b1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE and LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13528440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grade', True, 1),\n",
       " ('male', False, 3),\n",
       " ('raceeth', True, 1),\n",
       " ('preschool', False, 11),\n",
       " ('expectBachelors', True, 1),\n",
       " ('motherHS', False, 6),\n",
       " ('motherBachelors', False, 2),\n",
       " ('motherWork', False, 12),\n",
       " ('fatherHS', True, 1),\n",
       " ('fatherBachelors', True, 1),\n",
       " ('fatherWork', False, 10),\n",
       " ('selfBornUS', False, 13),\n",
       " ('motherBornUS', False, 4),\n",
       " ('fatherBornUS', False, 5),\n",
       " ('englishAtHome', False, 7),\n",
       " ('computerForSchoolwork', True, 1),\n",
       " ('read30MinsADay', True, 1),\n",
       " ('minutesPerWeekEnglish', True, 1),\n",
       " ('studentsInEnglish', False, 8),\n",
       " ('schoolHasLibrary', False, 9),\n",
       " ('publicSchool', True, 1),\n",
       " ('urban', False, 14),\n",
       " ('schoolSize', True, 1)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Running RFE with the output number of the variable equal to 10\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lm,n_features_to_select=10)             # running RFE\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dcc60ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           readingScore   R-squared:                       0.283\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     93.63\n",
      "Date:                Sat, 24 Dec 2022   Prob (F-statistic):          2.41e-163\n",
      "Time:                        13:49:20   Log-Likelihood:                 1264.5\n",
      "No. Observations:                2382   AIC:                            -2507.\n",
      "Df Residuals:                    2371   BIC:                            -2444.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     0.1532      0.021      7.250      0.000       0.112       0.195\n",
      "grade                     0.2231      0.023      9.710      0.000       0.178       0.268\n",
      "raceeth                   0.1329      0.012     11.221      0.000       0.110       0.156\n",
      "expectBachelors           0.0995      0.008     12.110      0.000       0.083       0.116\n",
      "motherBachelors           0.0220      0.007      2.967      0.003       0.007       0.037\n",
      "fatherHS                  0.0260      0.010      2.705      0.007       0.007       0.045\n",
      "fatherBachelors           0.0433      0.008      5.627      0.000       0.028       0.058\n",
      "motherBornUS             -0.0237      0.009     -2.743      0.006      -0.041      -0.007\n",
      "computerForSchoolwork     0.0390      0.011      3.571      0.000       0.018       0.060\n",
      "read30MinsADay            0.0680      0.006     10.551      0.000       0.055       0.081\n",
      "publicSchool             -0.0226      0.010     -2.165      0.030      -0.043      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                        1.921   Durbin-Watson:                   1.988\n",
      "Prob(Omnibus):                  0.383   Jarque-Bera (JB):                1.844\n",
      "Skew:                          -0.063   Prob(JB):                        0.398\n",
      "Kurtosis:                       3.052   Cond. No.                         23.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Creating X_test dataframe with RFE selected variables\n",
    "col = ['grade','raceeth','expectBachelors','motherBachelors','fatherHS','fatherBachelors','motherBornUS','computerForSchoolwork','read30MinsADay','publicSchool']\n",
    "X_train_rfe = X_train[col]\n",
    "\n",
    "# Adding a constant variable \n",
    "import statsmodels.api as sm  \n",
    "X_train_rfe = sm.add_constant(X_train_rfe)\n",
    "\n",
    "lm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model\n",
    "\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfb1af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Features        VIF\n",
      "0                   const  52.263214\n",
      "1                   grade   1.027453\n",
      "2                 raceeth   1.383522\n",
      "3         expectBachelors   1.116988\n",
      "4         motherBachelors   1.478825\n",
      "5                fatherHS   1.260773\n",
      "6         fatherBachelors   1.557503\n",
      "7            motherBornUS   1.484564\n",
      "8   computerForSchoolwork   1.071096\n",
      "9          read30MinsADay   1.018813\n",
      "10           publicSchool   1.060722\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_rfe\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7aa20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           readingScore   R-squared:                       0.283\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     93.63\n",
      "Date:                Sat, 24 Dec 2022   Prob (F-statistic):          2.41e-163\n",
      "Time:                        13:49:20   Log-Likelihood:                 1264.5\n",
      "No. Observations:                2382   AIC:                            -2507.\n",
      "Df Residuals:                    2371   BIC:                            -2444.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     0.1532      0.021      7.250      0.000       0.112       0.195\n",
      "grade                     0.2231      0.023      9.710      0.000       0.178       0.268\n",
      "raceeth                   0.1329      0.012     11.221      0.000       0.110       0.156\n",
      "expectBachelors           0.0995      0.008     12.110      0.000       0.083       0.116\n",
      "motherBachelors           0.0220      0.007      2.967      0.003       0.007       0.037\n",
      "fatherHS                  0.0260      0.010      2.705      0.007       0.007       0.045\n",
      "fatherBachelors           0.0433      0.008      5.627      0.000       0.028       0.058\n",
      "motherBornUS             -0.0237      0.009     -2.743      0.006      -0.041      -0.007\n",
      "computerForSchoolwork     0.0390      0.011      3.571      0.000       0.018       0.060\n",
      "read30MinsADay            0.0680      0.006     10.551      0.000       0.055       0.081\n",
      "publicSchool             -0.0226      0.010     -2.165      0.030      -0.043      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                        1.921   Durbin-Watson:                   1.988\n",
      "Prob(Omnibus):                  0.383   Jarque-Bera (JB):                1.844\n",
      "Skew:                          -0.063   Prob(JB):                        0.398\n",
      "Kurtosis:                       3.052   Cond. No.                         23.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                Features        VIF\n",
      "0                  grade  13.334303\n",
      "1                raceeth  10.784652\n",
      "2        expectBachelors   6.273012\n",
      "3        motherBachelors   2.295383\n",
      "4               fatherHS   9.107929\n",
      "5        fatherBachelors   2.357636\n",
      "6           motherBornUS   6.824334\n",
      "7  computerForSchoolwork  11.198686\n",
      "8         read30MinsADay   1.448749\n",
      "9           publicSchool   8.536986\n"
     ]
    }
   ],
   "source": [
    "X_train_new = X_train_rfe.drop([\"const\"], axis = 1)\n",
    "\n",
    "# Adding a constant variable \n",
    "import statsmodels.api as sm  \n",
    "X_train_lm = sm.add_constant(X_train_new)\n",
    "\n",
    "lm = sm.OLS(y_train,X_train_lm).fit()   # Running the linear model\n",
    "print(lm.summary())\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14baf634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the p-values and VIF are in the desired range, we’ll move forward with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "002f5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next step is the residual analysis of error terms.\n",
    "\n",
    "#Residual Analysis\n",
    "#So, let’s check if the error terms are also normally distributed using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b7c7612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_price = lm.predict(X_train_lm)\n",
    "# Importing the required libraries for plots.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.histplot((y_train - y_train_price), bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c15846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['minutesPerWeekEnglish', 'studentsInEnglish', 'schoolSize', 'readingScore','grade','raceeth']\n",
    "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
    "\n",
    "y_test = df_test.pop('readingScore')\n",
    "X_test = df_test\n",
    "\n",
    "# Now let's use our model to make predictions.\n",
    "\n",
    "# Creating X_test_new dataframe by dropping variables from X_test\n",
    "X_test_new = X_test[X_train_new.columns]\n",
    "# Adding a constant variable \n",
    "X_test_new = sm.add_constant(X_test_new)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = lm.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8538983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2823514158060685"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6578c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11335678625972335\n",
      "0.020431053528085375\n",
      "0.14293723632449795\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5b01274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The R² value for the test data = 0.6481740917926483, \n",
    "#which is pretty similar to the train data.\n",
    "\n",
    "#Since the R² values for both the train and \n",
    "#test data are almost equal, the model we built is the best-fitted model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
